---
title: '*Bromus* Density Dependence Analysis'
author: "Nick Gotelli"
date: "7/30/2019"
output:
  pdf_document: default
  html_document:
    highlight: tango
    theme: cerulean
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data sources and cleaning
These data were provided by Alden Griffith and Michael Loic. After talking with Alden, we decided to use $\lambda$ values that had been estimated from changes in the number of individuals in marked plots, rather than analysis of stage transition matrices. For a number of control plots, Alden and Michael have estimated lambda $(N_{t + 1}/N_{t})$ based on annual counts of cheatgrass for two consecutive years. For some of the plots, there are actually 7 consecutive years of data, but I am ignoring plot identity, and simply using $\lambda$ calculated for pair of consecutive abundances. For each of these measures, the variable `Starting.Density` gives $N_t$, the abundance in the first year.

For a simple logistic growth equation, there should be a negative linear relationship between  $r =        log(\lambda)$ and $N_t$.

I cleaned the initial data file (`Bromus Lambda and Climate Data.csv`), moving a notes column to initial comment lines, and adding 4 missing values as `NA`. The modified data are in `CleanBromusData.csv`.

```{r}
# Preliminaries -----------------------------------------------------------
library(tidyverse)

# Get input data ----------------------------------------------------------
df <- read.csv(file="../CleanData/CleanBromusData.csv",comment.char="#")
df <- df[,-ncol(df)]                 # remove empty final column
df_clean <- df[complete.cases(df),]  # remove 4 missing lambda

df_preds <- df_clean[,8:18]           # create dataframe of predictor variables
df_clean$r <- log(df_clean$Lambda)    # create response variable r from log(lambda)
```

## Initial regression models
With the data frame set up, the first analysis was to use each of the predictor variables (snow, degree-days, precipitation, etc.), with $r$ as the response variable. For each variable, I built a linear and a quadratic regression model.

```{r}
# Function Model Fit ------------------------------------------------------
# inputs: response variable, predictor variable
# outputs: adjusted r2 for linear and quadratic regression models

quad_fit <- function(x=df_clean$Snow.Cover, y=df_clean$r){
  M1 <- summary(lm(y~x))
  M2 <- summary(lm(y~poly(x,2)))
  return(c(M1$adj.r.squared,M2$adj.r.squared))
}
# -------------------------------------------------------------------------
# map all predictor variables to quad_fit
summary_df <- map(df_preds,quad_fit,y=df_clean$r)

# put into a summary data frame and add column labels
summary_df <- t(bind_rows(summary_df))
colnames(summary_df) <- c("Linear","Quadratic")
# -------------------------------------------------------------------------
```

## First screening of predictor variables
In this table, each row is a different model with a single predictor variable, and the data frame shows the adjusted r^2^ for each model. The two columns are for a linear model $(y \sim x)$ and a quadratic model $(y \sim x + x^2)$.

```{r}
print(summary_df)
```

A couple things jump out from these univariate regressions. First, the quadratic model often fits better than the corresponding linear model (even after imposing a penalty for the additional parameter), so we have good theoretical grounds and empirical support for going with the quadratic models.

The four strongest predictors were:

- snow cover (quadratic r^2^ = 0.838)
- winter precip total (quadratic r^2^ = 0.661)
- initial density (linear r^2^ = 0.638)
- growing season precipitation rain (quadratic r^2^ = 0.559)

I had originally intended to include one of the temperature variables, but they perform poorly compared to precip and snow cover variables, so we will start with just these initial 4. 


## Simple linear density dependence model

We start by ignoring all the climate variables and just fit the collection of annual $\lambda$ values to the linear function we expect for density dependence in a plain-vanilla logistic growth model:

```{r}
# best variables are:
# snow.cover (6)
# density (1)
# winter precip total. (11) 
# grow season precip rain (3)

best_preds <- df_preds[,c(6,1,11,3)]
  
y <- df_clean$r
x_1 <- best_preds[,1]
x_2 <- best_preds[,2]
x_3 <- best_preds[,3]
x_4 <- best_preds[,4]

final_df <- data.frame(r=y,
                       snow_cover=x_1,
                       density=x_2,
                       win_precip <- x_3,
                       gs_rain <- x_4)

model_dd <- summary(lm(data=final_df,r~density))
print(model_dd)
ggplot(data=final_df,aes(x=density,y=r)) +
  geom_point() +
  stat_smooth(method="lm", se=TRUE, fill=NA,
                formula=y ~ poly(x, 1, raw=TRUE),colour="red") 
```

These results look pretty nice. The relationship is roughly linear, and we pick up a sizeable chunk of the variation in $r$. The intercept is 1.206162, which corresponds to the maximum $r$ that occurs with no crowding ($N_t$ = 0). This is the constant $r$ that appears in the logistic growth equation. It is large ($\lambda = exp(r) = 3.34$), but reasonable for an annual plant. You can see there are some low-density plots that have even higher values than this.

The other parameter of interest is to set $r = 0$ and solve for $N$. This is the estimate of the carrying capacity $K$ in the logistic growth equation. For these data, we get K = 714 individuals.

Alden and Michael, do these values of $r = 1.21 individuals/individual\times year$ and $K = 714 individuals$ seem biologically reasonable for *Bromus**?  

## Quadratic density dependence model

The linear equation we fit above looks pretty good, but I wanted to check and see if there is any improvement by adding a quadratic term. The quadratic term might pop up if we have Allee effects generating inverse density dependence at low densities. This can occur in social animals with behaviors such as cooperative predator defense, cooperative hunting, and mate searching. For plants, you could see if it clumps of plants act as pollinator magnets and attract proportionally more pollinators than solitary plants. That doesn't seem likely for *Bromus*, but it is good to check the model.

```{r}
model_dd <- summary(lm(data=final_df,r~poly(density,2)))
print(model_dd)
ggplot(data=final_df,aes(x=density,y=r)) +
  geom_point() +
  stat_smooth(method="lm", se=TRUE, fill=NA,
                formula=y ~ poly(x, 2, raw=TRUE),colour="red") +
  stat_smooth(method="lm", se=TRUE, fill=NA,
                formula=y ~ poly(x, 1, raw=TRUE),colour="blue")
```

With one exception (see below), this output looks reasonable. The quadratic term is marginally non-significant (*p* = 0.10, and the quadratic fit does not look very different from the linear fit, except at very high densities, where the density dependence looks a little weaker than predicted by the linear model. Based on this comparison, I am comfortable with the linear model (a.k.a. logisitic growth) for estimating parameters for snow cover and other abiotic variables. Following up on a suggestion from Alden, in the continental forecasting model, we will actually fix N=0 for all plots. That way we are predicting lambda as a function of environmental variables for *Bromus* that are colonizing an empty pixel. There will not be any density effect in the continental forecast, but we do want the density effect when we fit the prediction functions to make sure we are not confounding abiotic effects with density effects in the original *Bromus* data.

## Trouble in the quadratic model

And now for the fly in the ointment. Take a look at the intercept coefficient in the fitted quadratic model. Its value is -0.0500. That seems dead wrong to me. Why isn't it something slightly larger than 1.2, the intercept for the linear model? In the graph you can see that those two estimates should be very similar to one another for the point at which N = 0. 

I can't see why the intercept estimates should be so far off. Note that this is a simple least-squares solution, so I am not using any kind of iterative fitting of a non-linear equation.

Can anyone figure out what is going on with these data? I suppose I could just ignore it because we are going to use the linear density model, but it makes me uneasy to see this kind of parameter fit. Your comments on this issue will be most appreciated!

